
Data Cleaning
Data import, importing Blanks, "NA" and "#DIV/0!" as NA's.

setwd("/Users/sharan/Desktop/Sharan/Coursera_R")
pmlTrain<-read.csv("pml-training.csv", header=T, na.strings=c("","NA", "#DIV/0!"))
pmlTest<-read.csv("pml-testing.csv", header=T, na.string=c("","NA", "#DIV/0!"))

Pre-proessing the training data set.Removing the variables with at least one "NA" from the analysis. Only 60 Variables left from initial 160.

noNATrain<-pmlTrain[, apply(pmlTrain, 2, function(x) !any(is.na(x)))] 
dim(noNATrain)

The variables which were related to time and user information also removed. Finally left with 52 variables.

cleanTrain<-noNATrain[,-c(1:8)]
dim(cleanTrain)

To predict the test 20 cases same variables were retained in Test data set (Validation Data set).

cleantest<-pmlTest[,names(cleanTrain[,-52])]
dim(cleantest)



Data Partition and Process
Partitioning the cleaned Training data set into 70% Training and 30% Test data sets. Random Forests Technique will be used to predict the outcome of this exercise.

library(caret)
inTrain<-createDataPartition(y=cleanTrain$classe, p=0.70,list=F)
training<-cleanTrain[inTrain,] 
test<-cleanTrain[-inTrain,] 
#Training and test set dimensions
dim(training)
dim(test)



Algorithm
Random Forest trees were generated for the 70% Training data set using cross-validation. 

library(caret)
set.seed(1234)
#Build trainControl for Cross - Validation
TC<-trainControl(method="cv", number=5, allowParallel=T, verbose=T)
TreeFit<-train(classe~.,data=training, method="rf", trControl=TC, verbose=F)

The algorithm was checked on the paritioned 30% Test data set to calculate the accuracy and estimated error of prediction.

TestPred<-predict(TreeFit,newdata=test)
confusionMatrix(TestPred,test$classe)



Project Submission
Predicting the output for 20 cases provided in the validation data set.

Val20<-predict(TreeFit,newdata=cleantest)
Val20

Writing 20 Files using the script provided.

setwd("/Users/sharan/Desktop/Sharan/Coursera_R")
getwd()
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(Val20)

Other Algorithms were also tested but Random Forest yields the best accuracy. The prediction for the 20 cases were also similar.



Conclusion
Out of Sample Error Estimation

outOfSampleError.accuracy<-sum(TestPred==test$classe)/length(TestPred)
outOfSampleError <- (1 - outOfSampleError.accuracy)*100
paste0("Out of sample error estimation: ", round(outOfSampleError,digits=2),"%")

The out of sample error estimation is 0.27%

Accuracy

paste0("Confusion Matrix accuracy estimation: ", round((outOfSampleError.accuracy)*100,digits=2),"%")

The Accuracy estimation is 99.73%
